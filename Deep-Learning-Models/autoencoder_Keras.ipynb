{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders [Keras]\n",
    "---\n",
    "- Author: Diego In√°cio\n",
    "- GitHub: [github.com/diegoinacio](https://github.com/diegoinacio)\n",
    "- Notebook: [autoencoder_Keras.ipynb](https://github.com/diegoinacio/machine-learning-notebooks/blob/master/Deep-Learning-Models/autoencoder_Keras.ipynb)\n",
    "---\n",
    "Implementation of *Autoencoders* using Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "[X_train, Y_train],[X_test, Y_test] = fashion_mnist.load_data()\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('Y_test:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label categories\n",
    "objects = [\n",
    "    'T-shirt/top', 'Trouser/pants',\n",
    "    'Pullover shirt', 'Dress',\n",
    "    'Coat', 'Sandal', 'Shirt',\n",
    "    'Sneaker', 'Bag', 'Ankle', 'boot'\n",
    "]\n",
    "\n",
    "# Get dimensions\n",
    "N1, N2 = X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, AX = plt.subplots(3, 6, sharex=True, sharey=True)\n",
    "\n",
    "np.random.seed(12345)\n",
    "for ax in AX.ravel():\n",
    "    rindex = np.random.randint(Y_train.size)\n",
    "    ax.imshow(X_train[rindex])\n",
    "    label = Y_train[rindex]\n",
    "    ax.set_title(f'{objects[label]} ({label})')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "# scales, dimensions and dtypes\n",
    "x_train, X_train = [X_train/255]*2\n",
    "x_test, X_test = [X_test/255]*2\n",
    "\n",
    "x_train = x_train.astype(np.float32).reshape(-1, N1*N2)\n",
    "X_train = X_train.astype(np.float32).reshape(-1, N1, N2, 1)\n",
    "x_test = x_test.astype(np.float32).reshape(-1, N1*N2)\n",
    "X_test = X_test.astype(np.float32).reshape(-1, N1, N2, 1)\n",
    "\n",
    "print('x_train:', x_train.shape)\n",
    "print('X_train:', X_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Autoencoder\n",
    "---\n",
    "![shallow autoencoder](sourceimages/autoencoder_shallow.png \"Shallow Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neurons on the bottleneck hidden layer\n",
    "neurons = 64\n",
    "\n",
    "# m is the number of examples\n",
    "# n_x is the input size 28x28=784\n",
    "m, n_x = x_train.shape\n",
    "\n",
    "# Model\n",
    "encoder_s = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(n_x),\n",
    "    tf.keras.layers.Dense(neurons, activation='relu')\n",
    "], name='Shallow-Encoder')\n",
    "\n",
    "decoder_s = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(neurons),\n",
    "    tf.keras.layers.Dense(n_x, activation='sigmoid')\n",
    "], name='Shallow-Decoder')\n",
    "\n",
    "\n",
    "autoencoder_s = tf.keras.Sequential([\n",
    "    encoder_s.input,\n",
    "    encoder_s.layers[0],\n",
    "    decoder_s.input,\n",
    "    decoder_s.layers[0]\n",
    "], name='Shallow-Autoencoder')\n",
    "\n",
    "autoencoder_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "autoencoder_s.compile(\n",
    "    optimizer='adadelta',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "for i in range(5):\n",
    "    print(f'\\nepochs: {i*100:04d} - {(i + 1)*100:04d}')\n",
    "    autoencoder_s.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=99,\n",
    "        verbose=0\n",
    "    )\n",
    "    autoencoder_s.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=1,\n",
    "        validation_data=(x_test, x_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, AX = plt.subplots(3, 6, figsize=(20, 10))\n",
    "\n",
    "np.random.seed(1234)\n",
    "for i in range(6):\n",
    "    index = np.argwhere(Y_test == i)[:,0]\n",
    "    index = np.random.choice(index)\n",
    "    label = Y_test[index]\n",
    "    \n",
    "    AX[0][i].imshow(X_test[index][...,0])\n",
    "    AX[0][i].set_title(f'{objects[label]} ({label})')\n",
    "    if not i: AX[0][i].set_ylabel('Input', size=16)\n",
    "    \n",
    "    encoded = encoder_s.predict(x_test[index].reshape(1, -1))\n",
    "    \n",
    "    AX[1][i].imshow(encoded.reshape(8, 8))\n",
    "    if not i: AX[1][i].set_ylabel('Encoded', size=16)\n",
    "    \n",
    "    decoded = decoder_s.predict(encoded)\n",
    "    \n",
    "    AX[2][i].imshow(decoded.reshape(N1, N2))\n",
    "    if not i: AX[2][i].set_ylabel('Decoded', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Autoencoder\n",
    "---\n",
    "![deep autoencoder](sourceimages/autoencoder_deep.png \"Deep Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m is the number of examples\n",
    "# n_x is the input size 28x28=784\n",
    "m, n_x = x_train.shape\n",
    "\n",
    "# Model\n",
    "encoder_d = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(n_x),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu')\n",
    "], name='Deep-Encoder')\n",
    "\n",
    "decoder_d = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(64),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_x, activation='sigmoid')\n",
    "], name='Deep-Decoder')\n",
    "\n",
    "\n",
    "autoencoder_d = tf.keras.Sequential([\n",
    "    encoder_d.input,\n",
    "    *encoder_d.layers,\n",
    "    decoder_d.input,\n",
    "    *decoder_d.layers\n",
    "], name='Deep-Autoencoder')\n",
    "\n",
    "autoencoder_d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "autoencoder_d.compile(\n",
    "    optimizer='adadelta',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "for i in range(5):\n",
    "    print(f'\\nepochs: {i*100:04d} - {(i + 1)*100:04d}')\n",
    "    autoencoder_d.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=99,\n",
    "        verbose=0\n",
    "    )\n",
    "    autoencoder_d.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, AX = plt.subplots(3, 6, figsize=(20, 10))\n",
    "\n",
    "np.random.seed(1234)\n",
    "for i in range(6):\n",
    "    index = np.argwhere(Y_test == i)[:,0]\n",
    "    index = np.random.choice(index)\n",
    "    label = Y_test[index]\n",
    "    \n",
    "    AX[0][i].imshow(X_test[index][...,0])\n",
    "    AX[0][i].set_title(f'{objects[label]} ({label})')\n",
    "    if not i: AX[0][i].set_ylabel('Input', size=16)\n",
    "    \n",
    "    encoded = encoder_d.predict(x_test[index].reshape(1, -1))\n",
    "    \n",
    "    AX[1][i].imshow(encoded.reshape(8, 8))\n",
    "    if not i: AX[1][i].set_ylabel('Encoded', size=16)\n",
    "    \n",
    "    decoded = decoder_d.predict(encoded)\n",
    "    \n",
    "    AX[2][i].imshow(decoded.reshape(N1, N2))\n",
    "    if not i: AX[2][i].set_ylabel('Decoded', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder\n",
    "---\n",
    "![convolutional autoencoder](sourceimages/autoencoder_convolutional.png \"Convolutional Autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid error: \"Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,\n",
    "#               so try looking to see if a warning log message was printed above.\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder_c = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Input((N1, N2, 1)),\n",
    "    tf.keras.layers.Convolution2D(16, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
    "    tf.keras.layers.Convolution2D(8, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same'),\n",
    "    tf.keras.layers.Convolution2D(3, kernel_size=(3,3), padding='same', activation='relu')\n",
    "], name='Convolutional-Encoder')\n",
    "\n",
    "decoder_c = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((7, 7, 3)),\n",
    "    tf.keras.layers.Convolution2D(8, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
    "    tf.keras.layers.Convolution2D(16, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
    "    tf.keras.layers.Convolution2D(1, kernel_size=(3,3), padding='same', activation='sigmoid')\n",
    "], name='Convolutional-Decoder')\n",
    "\n",
    "\n",
    "autoencoder_c = tf.keras.Sequential([\n",
    "    encoder_c.input,\n",
    "    *encoder_c.layers,\n",
    "    decoder_c.input,\n",
    "    *decoder_c.layers\n",
    "], name='Convolutional-Autoencoder')\n",
    "\n",
    "autoencoder_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "autoencoder_c.compile(\n",
    "    optimizer='adadelta',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "# Train model\n",
    "for i in range(5):\n",
    "    print(f'\\nepochs: {i*100:04d} - {(i + 1)*100:04d}')\n",
    "    autoencoder_c.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=99,\n",
    "        verbose=0\n",
    "    )\n",
    "    autoencoder_c.fit(\n",
    "        X_train, X_train,\n",
    "        epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, AX = plt.subplots(3, 6, figsize=(20, 10))\n",
    "\n",
    "np.random.seed(1234)\n",
    "for i in range(6):\n",
    "    index = np.argwhere(Y_test == i)[:,0]\n",
    "    index = np.random.choice(index)\n",
    "    label = Y_test[index]\n",
    "\n",
    "    AX[0][i].imshow(X_test[index][...,0])\n",
    "    AX[0][i].set_title(f'{objects[label]} ({label})')\n",
    "    if not i: AX[0][i].set_ylabel('Input', size=16)\n",
    "\n",
    "    encoded = encoder_c.predict(X_test[index][np.newaxis])\n",
    "    \n",
    "    AX[1][i].imshow(encoded[0]/encoded.max())\n",
    "    if not i: AX[1][i].set_ylabel('Encoded', size=16)\n",
    "    \n",
    "    decoded = decoder_c.predict(encoded)\n",
    "    \n",
    "    AX[2][i].imshow(decoded.reshape(N1, N2))\n",
    "    if not i: AX[2][i].set_ylabel('Decoded', size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
