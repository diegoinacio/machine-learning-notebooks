{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Approximation\n",
    "---\n",
    "- Author: Diego In√°cio\n",
    "- GitHub: [github.com/diegoinacio](https://github.com/diegoinacio)\n",
    "- Notebook: [image_approximation_deepNN.ipynb](https://github.com/diegoinacio/machine-learning-notebooks/blob/master/Practical-Applications/image_approximation_deepNN.ipynb)\n",
    "---\n",
    "*Image approximation* and *upscaling interpolation* using *deep Neural Network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (16, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = 128, 128\n",
    "# Read Image\n",
    "x = Image.open('_data/woman01.png')\n",
    "# Rescale image to a lower resolution\n",
    "x = x.resize((n1, n2), Image.ANTIALIAS)\n",
    "x = np.asarray(x)/255\n",
    "n1, n2, c = x.shape\n",
    "\n",
    "### split channels ###\n",
    "r, g, b = x[:,:,0], x[:,:,1], x[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data and produce X_train\n",
    "Y_train = np.array([r.ravel(), g.ravel(), b.ravel()]).T\n",
    "t, s = np.mgrid[0:n1, 0:n2]\n",
    "s = (s - s.mean())/s.std()\n",
    "t = (t - t.mean())/t.std()\n",
    "# X_train is the normalized spatial coordinates\n",
    "X_train = np.array([s.ravel(), t.ravel()], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axA, axB] = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "st = np.stack([s, t, s*0], axis=2)\n",
    "st = (st - st.min())/(st.max() - st.min())\n",
    "st[:,:,2] = 0; axA.imshow(st); axA.axis('off')\n",
    "axA.text(5, 10, f'({s.min():.3f}, {t.min():.3f})', color='white', size=18)\n",
    "axA.text(86, 10, f'({s.max():.3f}, {t.min():.3f})', color='white', size=18)\n",
    "axA.text(5, 120, f'({s.min():.3f}, {t.max():.3f})', color='white', size=18)\n",
    "axA.text(86, 120, f'({s.max():.3f}, {t.max():.3f})', color='white', size=18)\n",
    "axA.set_title(f'$X_{{train}}$ ({n1} x {n2})', size=20)\n",
    "\n",
    "axB.imshow(x)\n",
    "axB.set_title(f'$Y_{{train}}$ ({n1} x {n2})', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce X_test to another scale\n",
    "# Upscale the image approximation\n",
    "N1 = N2 = 512\n",
    "t, s = np.mgrid[0:N1, 0:N2]\n",
    "s = (s - s.mean())/s.std()\n",
    "t = (t - t.mean())/t.std()\n",
    "X_test = np.array([s.ravel(), t.ravel()], dtype=np.float32).T\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)\n",
    "print('X_test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid error: \"InternalError:  Blas GEMM launch failed...\" (RTX card)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of number of neurons for each hidden layer\n",
    "NEURONS = [2**i for i in range(5, 11)]\n",
    "\n",
    "# model \n",
    "# Input (2): x and y coordinates\n",
    "# Output (3): RGB\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(2),\n",
    "    *[tf.keras.layers.Dense(n, activation='relu') for n in NEURONS],\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "for i in range(5):\n",
    "    print(f'\\nepochs: {i*100:04d} - {(i + 1)*100:04d}')\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=99,\n",
    "        verbose=0\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [axA, axB] = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "axA.imshow(x)\n",
    "axA.set_title(f'$Y_{{train}}$ ({n1} x {n2})', size=20)\n",
    "# Predict using X_train (128x128x3)\n",
    "Y_predA = model.predict(X_train)\n",
    "Y_predA = Y_predA.reshape(n1, n2, c)\n",
    "axB.imshow(Y_predA)\n",
    "axB.set_title(f'$\\hat{{Y}}_{{train}}$ ({n1} x {n2})', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axA = plt.subplots(1, 1, figsize=(20, 20))\n",
    "\n",
    "# Predict using X_test (512x512x3)\n",
    "Y_predB = model.predict(X_test)\n",
    "Y_predB = Y_predB.reshape(N1, N2, c)\n",
    "axA.imshow(Y_predB)\n",
    "axA.set_title(f'$\\hat{{Y}}_{{test}}$ ({N1} x {N2})', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning process visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    '<iframe width=\"960\" height=\"540\" src=\"https://www.youtube.com/embed/3RplSSsfWK4\" frameborder=\"0\" allowfullscreen></iframe>'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
